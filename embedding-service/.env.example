# OpenAI
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_API_URL=https://api.openai.com/v1

# --- New Embedding Model Configuration ---
EMBEDDING_PROVIDER="gemini"                # Can be "openai" or "gemini"
OPENAI_EMBED_MODEL_NAME="text-embedding-3-small" # New default model
GEMINI_API_KEY=your-gemini-api-key-here # For Gemini integration
GEMINI_EMBED_MODEL_NAME="text-embedding-004"    # Example for Gemini
EMBEDDING_BATCH_SIZE=32              # Default batch size

LLM_PROVIDER="gemini" # or "openai"

# Embedding + Chunking (OPENAI_EMBED_MODEL is now OPENAI_EMBED_MODEL_NAME)
CHUNK_SIZE=2000 # Your current CHUNK_SIZE. Consider if this is token or char count.
                 # If char count, text-embedding-3-small has an 8191 token limit per item.
                 # 14000 chars might be too large for a single embedding input.
EMBED_DIM=768  # Stays 1536 for text-embedding-3-small or 768 for gemini-embedding-001

# OpenSearch
OPENSEARCH_HOST=opensearch
OPENSEARCH_PORT=9200
OPENSEARCH_INDEX_NAME="knowledge_base" # Or your preferred index name
ENABLE_CONTEXT_GENERATION=false

# Upload Limits
MAX_FILE_SIZE=10485760
MAX_FILES_PER_REQUEST=5

# Local Paths
TEMP_DIR=./temp
UPLOAD_DIR=./uploads

# Optional: Add PORT if not already present from your index.js
PORT=8001